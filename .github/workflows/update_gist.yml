name: Update YouTube Live List

on:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch: {}

permissions:
  contents: read

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: pip install --upgrade yt-dlp requests

      - name: Prepare cookies (Netscape format)
        env:
          COOKIES_CONTENT: ${{ secrets.YT_COOKIES }}
        run: |
          if [ -n "$COOKIES_CONTENT" ]; then
            echo "$COOKIES_CONTENT" > cookies.txt
          fi

      - name: Normalize channels.txt
        run: |
          if [ -f channels.txt ]; then
            tr -d '\r' < channels.txt > channels_unix.txt
            mv channels_unix.txt channels.txt
          else
            echo "‚ö†Ô∏è channels.txt bulunamadƒ±!"
            exit 1
          fi

      - name: Fetch existing gist metadata
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          if [ -z "$GIST_ID" ] || [ -z "$GIST_TOKEN" ]; then
            echo "‚ö†Ô∏è Gist eri≈üim bilgileri eksik."
            exit 1
          fi
          curl -s -H "Authorization: token ${GIST_TOKEN}" \
            https://api.github.com/gists/${GIST_ID} > gist.json

      - name: Update each channel as separate .m3u8
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          set -e

          update_channel() {
            LINE="$1"
            IFS=',' read -r CHANNEL_HANDLE FILE_NAME <<< "$LINE"
            [ -z "$CHANNEL_HANDLE" ] && return
            [[ "$CHANNEL_HANDLE" != @* && ! "$CHANNEL_HANDLE" =~ ^UC ]] && CHANNEL_HANDLE="@${CHANNEL_HANDLE}"

            if [[ "$CHANNEL_HANDLE" =~ ^UC ]]; then
              YT_URL="https://www.youtube.com/channel/${CHANNEL_HANDLE}/live"
            else
              YT_URL="https://www.youtube.com/${CHANNEL_HANDLE}/live"
            fi

            echo "üîç $CHANNEL_HANDLE kontrol ediliyor..."
            sleep $((RANDOM % 5 + 2))  # 2-6 saniye rastgele gecikme

            if [ -f cookies.txt ]; then
              META=$(yt-dlp --cookies cookies.txt --no-warnings --skip-download "$YT_URL" --print "%(is_live)s %(id)s" 2>/dev/null || true)
            else
              META=$(yt-dlp --no-warnings --skip-download "$YT_URL" --print "%(is_live)s %(id)s" 2>/dev/null || true)
            fi

            if echo "$META" | grep -q "True"; then
              VID_ID=$(echo "$META" | awk '{print $2}')
              echo "üì∫ Yayƒ±n bulundu: $VID_ID"

              # T√ºm kalite linklerini tek istekte al
              if [ -f cookies.txt ]; then
                URL_LIST=$(yt-dlp --cookies cookies.txt --no-warnings --skip-download --all-formats --get-url "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null)
              else
                URL_LIST=$(yt-dlp --no-warnings --skip-download --all-formats --get-url "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null)
              fi

              echo "#EXTM3U" > "$FILE_NAME"
              echo "# Kanal: $CHANNEL_HANDLE" >> "$FILE_NAME"
              echo "# Otomatik olu≈üturulma: $(date '+%Y-%m-%d %H:%M:%S')" >> "$FILE_NAME"

              # JSON format listesini al
if [ -f cookies.txt ]; then
  yt-dlp --cookies cookies.txt --no-warnings --skip-download -J "https://www.youtube.com/watch?v=${VID_ID}" > formats.json
else
  yt-dlp --no-warnings --skip-download -J "https://www.youtube.com/watch?v=${VID_ID}" > formats.json
fi

echo "#EXTM3U" > "$FILE_NAME"
echo "# Kanal: $CHANNEL_HANDLE" >> "$FILE_NAME"
echo "# Otomatik olu≈üturulma: $(date '+%Y-%m-%d %H:%M:%S')" >> "$FILE_NAME"

python3 << 'EOF'
import json

# JSON oku
with open("formats.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# M3U8 √ßƒ±ktƒ±sƒ±nƒ± a√ß
out = open("$FILE_NAME", "a", encoding="utf-8")

for fmt in data.get("formats", []):
    url = fmt.get("url")
    if not url:
        continue

    # Toplam bitrate (tbr varsa onu al, yoksa abr)
    bw = fmt.get("tbr") or fmt.get("abr") or 0

    width = fmt.get("width") or 0
    height = fmt.get("height") or 0

    out.write(f"#EXT-X-STREAM-INF:BANDWIDTH={int(bw*1000)},RESOLUTION={width}x{height}\n")
    out.write(url + "\n")

out.close()
EOF

rm -f formats.json

              echo "‚úÖ $FILE_NAME g√ºncellendi"

              CONTENT_JSON=$(python3 -c "import json; print(json.dumps(open('$FILE_NAME','r',encoding='utf-8').read()))")
              PAYLOAD="{\"files\": {\"$FILE_NAME\": {\"content\": $CONTENT_JSON}}}"

              curl -s -X PATCH \
                -H "Authorization: token ${GIST_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${PAYLOAD}" \
                "https://api.github.com/gists/${GIST_ID}" > /dev/null

            else
              echo "‚ùå Yayƒ±n bulunamadƒ±: $CHANNEL_HANDLE"
            fi
          }

          export -f update_channel
          cat channels.txt | grep -vE '^\s*#' | xargs -n1 -P1 -I {} bash -c 'update_channel "$@"' _ {}

          [ -f cookies.txt ] && rm -f cookies.txt

      - name: Temizlik
        run: |
          rm -f formats.txt gist.json || true
          echo "üßπ Temizlik tamamlandƒ±."
