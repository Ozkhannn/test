name: Update YouTube Live List

on:
  schedule:
    - cron: "*/5 * * * *"   # Her 5 dakikada bir çalışır
  workflow_dispatch:

permissions:
  contents: read

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install --upgrade yt-dlp requests

      - name: Prepare cookies
        env:
          COOKIES_CONTENT: ${{ secrets.YT_COOKIES }}
        run: |
          if [ -n "$COOKIES_CONTENT" ]; then
            echo "$COOKIES_CONTENT" > cookies.txt
          fi

      - name: Normalize channels.txt
        run: |
          if [ -f channels.txt ]; then
            tr -d '\r' < channels.txt > channels_unix.txt
            mv channels_unix.txt channels.txt
          else
            echo "channels.txt bulunamadı!"
            exit 1
          fi

      - name: Create update script
        run: |
          cat > update_live.py <<'PYCODE'
import yt_dlp
import json
import sys

channels = []
with open("channels.txt", "r", encoding="utf-8") as f:
    for line in f:
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        parts = [x.strip() for x in line.split(",", 2)]
        if len(parts) != 3:
            continue
        handle, name, quality = parts
        if not handle.startswith("@"):
            handle = "@" + handle
        channels.append((handle, name, quality))

with open("live.m3u", "r", encoding="utf-8") as f:
    lines = f.readlines()

existing_links = {}
for i, line in enumerate(lines):
    if line.startswith("#EXTINF:"):
        display_name = line.split(",")[1].split(" [")[0].strip()
        if i + 1 < len(lines):
            existing_links[display_name] = i + 1

for handle, display_name, quality in channels:
    ydl_opts = {"quiet": True, "skip_download": True}
    url = f"https://www.youtube.com/{handle}/live"
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            info = ydl.extract_info(url, download=False)
            if info.get("is_live"):
                live_url = info.get("webpage_url")
                if display_name in existing_links:
                    lines[existing_links[display_name]] = live_url + "\n"
                else:
                    lines.append(f"#EXTINF:-1,{display_name} [{quality}]\n")
                    lines.append(live_url + "\n")
        except Exception:
            pass

with open("live.m3u", "w", encoding="utf-8") as f:
    f.writelines(lines)
PYCODE

      - name: Merge/update live.m3u with existing Gist
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          set -e

          EXISTING=$(curl -s -H "Authorization: token $GIST_TOKEN" \
            "https://api.github.com/gists/$GIST_ID" \
            | python3 -c "import sys,json; print(json.load(sys.stdin)['files']['live.m3u']['content'])" \
            || echo "#EXTM3U\n")

          echo "$EXISTING" > live.m3u

          python3 update_live.py

          [ -f cookies.txt ] && rm -f cookies.txt

      - name: Update Gist
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          if [ -z "$GIST_ID" ] || [ -z "$GIST_TOKEN" ]; then
            echo "GIST_ID veya GIST_TOKEN eksik."
            exit 0
          fi

          CONTENT_JSON=$(python3 -c "import json; print(json.dumps(open('live.m3u','r',encoding='utf-8').read()))")

          PAYLOAD="{\"files\":{\"live.m3u\":{\"content\":$CONTENT_JSON}}}"

          HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" \
            -X PATCH \
            -H "Authorization: token ${GIST_TOKEN}" \
            -H "Content-Type: application/json" \
            -d "${PAYLOAD}" \
            "https://api.github.com/gists/${GIST_ID}")

          echo "Gist update HTTP status: $HTTP_STATUS"
