name: Update YouTube Live List

on:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch: {}

permissions:
  contents: read

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: pip install --no-cache-dir --upgrade yt-dlp requests

      - name: Prepare cookies (Netscape format)
        env:
          COOKIES_CONTENT: ${{ secrets.YT_COOKIES }}
        run: |
          if [ -n "$COOKIES_CONTENT" ]; then
            echo "$COOKIES_CONTENT" > cookies.txt
          fi

      - name: Normalize channels.txt
        run: |
          if [ -f channels.txt ]; then
            tr -d '\r' < channels.txt > channels_unix.txt
            mv channels_unix.txt channels.txt
          else
            echo "‚ö†Ô∏è channels.txt bulunamadƒ±!"
            exit 1
          fi

      - name: Fetch existing gist metadata
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          if [ -z "$GIST_ID" ] || [ -z "$GIST_TOKEN" ]; then
            echo "‚ö†Ô∏è Gist eri≈üim bilgileri eksik."
            exit 1
          fi
          curl -s -H "Authorization: token ${GIST_TOKEN}" \
            https://api.github.com/gists/${GIST_ID} > gist.json

      - name: Update each channel as single .m3u8
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          set -e

          update_channel() {
            LINE="$1"
            IFS=',' read -r CHANNEL_HANDLE FILE_NAME <<< "$LINE"
            [ -z "$CHANNEL_HANDLE" ] && return
            [[ "$CHANNEL_HANDLE" != @* && ! "$CHANNEL_HANDLE" =~ ^UC ]] && CHANNEL_HANDLE="@${CHANNEL_HANDLE}"

            if [[ "$CHANNEL_HANDLE" =~ ^UC ]]; then
              YT_URL="https://www.youtube.com/channel/${CHANNEL_HANDLE}/live"
            else
              YT_URL="https://www.youtube.com/${CHANNEL_HANDLE}/live"
            fi

            echo "üîç $CHANNEL_HANDLE kontrol ediliyor..."
            sleep $((RANDOM % 2 + 2))

            META=$( [ -f cookies.txt ] && yt-dlp --cookies cookies.txt -J "https://www.youtube.com/${CHANNEL_HANDLE}" 2>/dev/null | jq -r '.entries[] | select(.is_live==true) | [.is_live, .id] | @tsv' || yt-dlp -J "https://www.youtube.com/${CHANNEL_HANDLE}" 2>/dev/null | jq -r '.entries[] | select(.is_live==true) | [.is_live, .id] | @tsv' )

            if echo "$META" | grep -q "True"; then
              VID_ID=$(echo "$META" | awk '{print $2}')
              echo "üì∫ Yayƒ±n bulundu: $VID_ID"

              # T√ºm formatlarƒ± tek istekte al
              FORMATS=$( [ -f cookies.txt ] && yt-dlp --cookies cookies.txt --no-warnings --skip-download -F "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null | grep '^[0-9]' || yt-dlp --no-warnings --skip-download -F "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null | grep '^[0-9]' )

              # URL'leri tek seferde al
              URLS=$(echo "$FORMATS" | awk '{print $1}' | tr '\n' ',' | sed 's/,$//')
              URL_LIST=$( [ -f cookies.txt ] && yt-dlp --cookies cookies.txt --no-warnings --skip-download -f "$URLS" --get-url "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null || yt-dlp --no-warnings --skip-download -f "$URLS" --get-url "https://www.youtube.com/watch?v=${VID_ID}" 2>/dev/null )

              echo "#EXTM3U" > "$FILE_NAME"
              echo "# Kanal: $CHANNEL_HANDLE" >> "$FILE_NAME"
              echo "# Otomatik olu≈üturulma: $(date '+%Y-%m-%d %H:%M:%S')" >> "$FILE_NAME"

              i=1
              while read -r fmt; do
                FMT_ID=$(echo "$fmt" | awk '{print $1}')
                RES=$(echo "$fmt" | grep -oE '[0-9]+x[0-9]+' | head -n1)
                BW=$(echo "$fmt" | grep -oE '[0-9]+k' | head -n1 | tr -d 'k')
                URL=$(echo "$URL_LIST" | sed -n "${i}p")
                [ -z "$URL" ] && continue
                echo "#EXT-X-STREAM-INF:BANDWIDTH=$((BW*1000)),RESOLUTION=${RES}" >> "$FILE_NAME"
                echo "$URL" >> "$FILE_NAME"
                i=$((i+1))
              done <<< "$FORMATS"

              echo "‚úÖ $FILE_NAME g√ºncellendi"

              CONTENT_JSON=$(python3 -c "import json; print(json.dumps(open('$FILE_NAME','r',encoding='utf-8').read()))")
              PAYLOAD="{\"files\": {\"$FILE_NAME\": {\"content\": $CONTENT_JSON}}}"

              curl -s -X PATCH \
                -H "Authorization: token ${GIST_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${PAYLOAD}" \
                "https://api.github.com/gists/${GIST_ID}" > /dev/null

            else
              echo "‚ùå Yayƒ±n bulunamadƒ±: $CHANNEL_HANDLE"
            fi
          }

          export -f update_channel
          cat channels.txt | grep -vE '^\s*#' | xargs -n1 -P3 -I {} bash -c 'update_channel "$@"' _ {}

          [ -f cookies.txt ] && rm -f cookies.txt

      - name: Temizlik
        run: |
          rm -f formats.txt gist.json || true
          echo "üßπ Temizlik tamamlandƒ±."
