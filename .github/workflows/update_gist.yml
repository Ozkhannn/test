name: Update YouTube Gist Streams

on:
  schedule:
    - cron: "*/10 * * * *"
  workflow_dispatch: {}

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install --upgrade yt-dlp requests

      - name: Prepare cookies
        env:
          COOKIES_CONTENT: ${{ secrets.YT_COOKIES }}
        run: |
          if [ -n "$COOKIES_CONTENT" ]; then
            echo "$COOKIES_CONTENT" > cookies.txt
          fi

      - name: Update Gist manifests
        env:
          GIST_ID: ${{ secrets.GIST_ID }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          echo "Başlatılıyor..."
          python - <<'PYCODE' import os, json, subprocess, requests

gist_id = os.getenv("GIST_ID")
token = os.getenv("GIST_TOKEN")
cookies = "cookies.txt" if os.path.exists("cookies.txt") else None
if not gist_id or not token:
    raise SystemExit("❌ GIST_ID veya GIST_TOKEN eksik.")

def run(cmd):
    try:
        return subprocess.check_output(cmd, text=True, stderr=subprocess.DEVNULL).strip()
    except:
        return ""

def live_id(ch):
    url = f"https://www.youtube.com/{ch}/live" if ch.startswith("@") else f"https://www.youtube.com/channel/{ch}/live"
    cmd = ["yt-dlp","--no-warnings","--skip-download","--print","%(is_live)s %(id)s",url]
    if cookies: cmd.insert(1,"--cookies"); cmd.insert(2,cookies)
    out = run(cmd)
    if out.startswith("True"):
        return out.split()[1]
    return None

def manifest(urls):
    bw = {"144":"150000","240":"400000","360":"800000","480":"1200000","720":"2500000","1080":"4500000"}
    res = {"144":"256x144","240":"426x240","360":"640x360","480":"854x480","720":"1280x720","1080":"1920x1080"}
    lines=["#EXTM3U","#EXT-X-VERSION:3"]
    for q in ["144","240","360","480","720","1080"]:
        if q in urls:
            lines.append(f'#EXT-X-STREAM-INF:BANDWIDTH={bw[q]},RESOLUTION={res[q]}')
            lines.append(urls[q])
    return "\n".join(lines)

def get_urls(video_id):
    urls={}
    base=f"https://www.youtube.com/watch?v={video_id}"
    for q in ["144","240","360","480","720","1080"]:
        fmt=f"bestvideo[height<={q}]+bestaudio/best[height<={q}]/best"
        cmd=["yt-dlp","--no-warnings","--skip-download","-f",fmt,"--get-url",base]
        if cookies: cmd.insert(1,"--cookies"); cmd.insert(2,cookies)
        out=run(cmd)
        if out: urls[q]=out.splitlines()[0]
    return urls

if not os.path.exists("channels.txt"):
    raise SystemExit("⚠️ channels.txt yok")

files = {}
for line in open("channels.txt"):
    if not line.strip() or line.startswith("#"): continue
    ch,gfile=[p.strip() for p in line.split(",")]
    print(f"[▶] {ch} işleniyor...")
    vid=live_id(ch)
    if not vid:
        print(f"❌ {ch}: canlı değil")
        continue
    urls=get_urls(vid)
    if not urls:
        print(f"❌ {ch}: link alınamadı")
        continue
    files[gfile]={"content":manifest(urls)}
    print(f"✅ {ch}: {len(urls)} kalite bulundu")

if not files:
    raise SystemExit("❌ Hiçbir kanal bulunamadı")

print("⏫ Gist güncelleniyor...")
resp=requests.patch(
    f"https://api.github.com/gists/{gist_id}",
    headers={"Authorization":f"token {token}","Accept":"application/vnd.github+json"},
    data=json.dumps({"files":files})
)
print("HTTP:",resp.status_code)
if resp.status_code>=300:
    print(resp.text)
else:
    print("✅ Gist güncellendi.")
PYCODE
